{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验——逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 任务分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question：应用逻辑回归算法识别乳腺癌。\n",
    "乳腺癌是一种发于腺上皮组织的恶性肿瘤，居女性恶性肿瘤的第1位。原位的乳腺癌并不致命，但随着癌变进一步发展，形成的乳腺癌细胞连接较为松散，容易脱落，之后便随着血液扩散到全身危及生命. 如果有能根据某些特征识别出乳腺癌以及乳腺癌类型的方法，那么将极大地帮助对疾病进行早发现以及针对性治疗. （数据集为sklearn库自带乳腺癌数据集，使用load_breast_cancer()函数可加载该数据集）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1 查看数据集\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import datasets  # 导入库\n",
    "dataset = datasets.load_breast_cancer()  # 导入乳腺癌数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集维度：(569, 30)\n",
      "测试集维度：(569, 1)\n"
     ]
    }
   ],
   "source": [
    "#character\n",
    "train = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "#label\n",
    "test = pd.DataFrame(dataset.target)\n",
    "test = test.rename(columns={0:'target'})\n",
    "# 查看训练集,测试集数据维度\n",
    "print(f'训练集维度：{train.shape}')\n",
    "print(f'测试集维度：{test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                   0.07871        1.0950         0.9053            8.589   \n",
       "1                   0.05667        0.5435         0.7339            3.398   \n",
       "2                   0.05999        0.7456         0.7869            4.585   \n",
       "566                 0.05648        0.4564         1.0750            3.425   \n",
       "567                 0.07016        0.7260         1.5950            5.772   \n",
       "568                 0.05884        0.3857         1.4280            2.548   \n",
       "\n",
       "     area error  smoothness error  compactness error  concavity error  \\\n",
       "0        153.40          0.006399            0.04904          0.05373   \n",
       "1         74.08          0.005225            0.01308          0.01860   \n",
       "2         94.03          0.006150            0.04006          0.03832   \n",
       "566       48.55          0.005903            0.03731          0.04730   \n",
       "567       86.22          0.006522            0.06158          0.07117   \n",
       "568       19.15          0.007189            0.00466          0.00000   \n",
       "\n",
       "     concave points error  symmetry error  fractal dimension error  \\\n",
       "0                 0.01587         0.03003                 0.006193   \n",
       "1                 0.01340         0.01389                 0.003532   \n",
       "2                 0.02058         0.02250                 0.004571   \n",
       "566               0.01557         0.01318                 0.003892   \n",
       "567               0.01664         0.02324                 0.006185   \n",
       "568               0.00000         0.02676                 0.002783   \n",
       "\n",
       "     worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0          25.380          17.33           184.60      2019.0   \n",
       "1          24.990          23.41           158.80      1956.0   \n",
       "2          23.570          25.53           152.50      1709.0   \n",
       "566        18.980          34.12           126.70      1124.0   \n",
       "567        25.740          39.42           184.60      1821.0   \n",
       "568         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#显示所有特征列\n",
    "pd.set_option('display.max_columns',None)\n",
    "#查看训练集数据\n",
    "train.head(3).append(train.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "566       0\n",
       "567       0\n",
       "568       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看测试集数据\n",
    "test.head(3).append(test.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看label分布\n",
    "test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n",
      "None\n",
      "-------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   target  569 non-null    int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 2.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#查看数据类型\n",
    "print(train.info())\n",
    "print('-------------------------------------')\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 特征列数据无空值，数据类型均为float64\n",
    "* 标签列数据无空值，数据类型为int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>2.873000</td>\n",
       "      <td>4.885000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>542.200000</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  radius error  texture error  \\\n",
       "count     569.000000              569.000000    569.000000     569.000000   \n",
       "mean        0.181162                0.062798      0.405172       1.216853   \n",
       "std         0.027414                0.007060      0.277313       0.551648   \n",
       "min         0.106000                0.049960      0.111500       0.360200   \n",
       "25%         0.161900                0.057700      0.232400       0.833900   \n",
       "50%         0.179200                0.061540      0.324200       1.108000   \n",
       "75%         0.195700                0.066120      0.478900       1.474000   \n",
       "max         0.304000                0.097440      2.873000       4.885000   \n",
       "\n",
       "       perimeter error  area error  smoothness error  compactness error  \\\n",
       "count       569.000000  569.000000        569.000000         569.000000   \n",
       "mean          2.866059   40.337079          0.007041           0.025478   \n",
       "std           2.021855   45.491006          0.003003           0.017908   \n",
       "min           0.757000    6.802000          0.001713           0.002252   \n",
       "25%           1.606000   17.850000          0.005169           0.013080   \n",
       "50%           2.287000   24.530000          0.006380           0.020450   \n",
       "75%           3.357000   45.190000          0.008146           0.032450   \n",
       "max          21.980000  542.200000          0.031130           0.135400   \n",
       "\n",
       "       concavity error  concave points error  symmetry error  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.031894              0.011796        0.020542   \n",
       "std           0.030186              0.006170        0.008266   \n",
       "min           0.000000              0.000000        0.007882   \n",
       "25%           0.015090              0.007638        0.015160   \n",
       "50%           0.025890              0.010930        0.018730   \n",
       "75%           0.042050              0.014710        0.023480   \n",
       "max           0.396000              0.052790        0.078950   \n",
       "\n",
       "       fractal dimension error  worst radius  worst texture  worst perimeter  \\\n",
       "count               569.000000    569.000000     569.000000       569.000000   \n",
       "mean                  0.003795     16.269190      25.677223       107.261213   \n",
       "std                   0.002646      4.833242       6.146258        33.602542   \n",
       "min                   0.000895      7.930000      12.020000        50.410000   \n",
       "25%                   0.002248     13.010000      21.080000        84.110000   \n",
       "50%                   0.003187     14.970000      25.410000        97.660000   \n",
       "75%                   0.004558     18.790000      29.720000       125.400000   \n",
       "max                   0.029840     36.040000      49.540000       251.200000   \n",
       "\n",
       "        worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       worst concave points  worst symmetry  worst fractal dimension  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#统计学角度观察数据\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 各特征列数量均为569，无空值、缺失值\n",
    "* 通过观察min，25%，50%，75%，max，发现数据分布均匀，不需要进行纠偏处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、使用自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, theta):\n",
    "return sigmoid(np.dot(X, theta.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, theta):\n",
    "    left = np.multiply(-y, np.log(model(X, theta)))\n",
    "    right = np.multiply(1 - y, np.log(1 - model(X, theta)))\n",
    "return np.sum(left - right) / (len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y, theta):\n",
    "    grad = np.zeros(theta.shape)\n",
    "    error = (model(X, theta)- y).ravel()\n",
    "    for j in range(len(theta.ravel())): #for each parmeter\n",
    "        term = np.multiply(error, X[:,j])\n",
    "        grad[0, j] = np.sum(term) / len(X)\n",
    "    \n",
    "return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 逻辑斯蒂回归是二分类方法,但sklearn中的逻辑斯蒂回归函数实现了多分类算法。\n",
    "* 逻辑斯蒂回归本质上也是一种线性分类器，就是用线性函数曲线将超平面分成两部分。和上边讲的内容一样，通过增加多项式特征也可以实现非线性分类。\n",
    "* from sklearn.linear_model import LogisticRegression 这个分类器可以设置正则化功能,但只能做L2正则化。  \n",
    "* from sklearn.linear_model import LogisticRegressionCV 带有参数遍历功能选择超参数alpha  \n",
    "* from sklearn.linear_model import SGDClassifier  可以设置正则化功能，并且是随机梯度分类器,数据量大的时候用这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###数据分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, test, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(143, 30)\n",
      "(426, 1)\n",
      "(143, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各项系数为：[[ 0.58944681  0.32354707  0.34378517 -0.01958101 -0.01636795 -0.09597013\n",
      "  -0.13621397 -0.05523724 -0.03067836 -0.00416156  0.02955644  0.09723722\n",
      "   0.05506978 -0.07197287 -0.00157726 -0.02197864 -0.03253905 -0.0081524\n",
      "  -0.00807836 -0.00182907  0.66658903 -0.34513701 -0.2205526  -0.01225753\n",
      "  -0.02816869 -0.28898206 -0.37326943 -0.11003405 -0.08190132 -0.0230356 ]]\n",
      "常数项为：[0.10818911]\n",
      "train_score= 0.9366197183098591\n",
      "test_score= 0.9370629370629371\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        55\n",
      "           1       0.94      0.95      0.95        88\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "#模型方法使用L2正则\n",
    "clf_model = LogisticRegression(penalty='l2',random_state=33)\n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "print(f'各项系数为：{clf_model.coef_}')\n",
    "print(f'常数项为：{clf_model.intercept_}')\n",
    "\n",
    "#预测测试集各样本的类别\n",
    "y_pred1=clf_model.predict(X_test)\n",
    "#预测测试集每个样本属于各类的概率\n",
    "y_pred2=clf_model.predict_proba(X_test)\n",
    "\n",
    "#训练集得分\n",
    "train_score = clf_model.score(X_train, y_train)\n",
    "#测试集得分\n",
    "test_score = clf_model.score(X_test, y_test)\n",
    "\n",
    "print('train_score=',train_score)\n",
    "print('test_score=',test_score)\n",
    "print('------------------------------------------------------')\n",
    "y_predict=clf_model.predict(X_test)\n",
    "\n",
    "'''\n",
    "#使用从classification_report展示各种评价指标包含（\n",
    "from sklearn.metrics import accuracy_score   #正确率\n",
    "from sklearn.metrics import precision_score    #精准率\n",
    "from sklearn.metrics import recall_score      #召回率\n",
    "from sklearn.metrics import f1_score         #调和平均值F1\n",
    "）\n",
    "'''\n",
    "model_report=classification_report(y_test,y_predict)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score= 0.9694835680751174\n",
      "test_score= 0.958041958041958\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        55\n",
      "           1       0.97      0.97      0.97        88\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用增加多项式特征方法模型优化\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 增加多项式预处理\n",
    "def polynomial_model(degree=1, **kwarg):\n",
    "    polynomial_features = PolynomialFeatures(degree=degree,include_bias=False)\n",
    "    logistic_regression = LogisticRegression(**kwarg)\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),(\"logistic_regression\", logistic_regression)])\n",
    "    return pipeline\n",
    "\n",
    "clf_model = polynomial_model(degree=2, #指定多项式特征的最大次数\n",
    "                         penalty='l2', #正则化方法\n",
    "                         max_iter=200,   #求解器收敛的最大迭代次数\n",
    "                         random_state=33) \n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "#训练集得分\n",
    "train_score = clf_model.score(X_train, y_train)\n",
    "#测试集得分\n",
    "test_score = clf_model.score(X_test, y_test)\n",
    "\n",
    "print('train_score=', train_score)\n",
    "print('test_score=',test_score)\n",
    "print('-------------------------------------------------------')\n",
    "y_predict=clf_model.predict(X_test)\n",
    "model_report=classification_report(y_test,y_predict)\n",
    "print(model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对比发现，将模型进行优化后，各评价指标显著提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_loss, test_loss = learning_curve( clf_model, X_train, y_train, cv=10,\n",
    "train_sizes=[0.1, 0.25, 0.5, 0.75, 1])\n",
    "train_loss_mean = 1-np.mean(train_loss, axis=1)\n",
    "test_loss_mean = 1-np.mean(test_loss, axis=1)\n",
    "plt.plot(train_sizes, train_loss_mean, 'o-', color=\"r\",\n",
    "         label=\"Train\")\n",
    "plt.plot(train_sizes, test_loss_mean, 'o-', color=\"g\",\n",
    "        label=\"Test\")\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据学习曲线可以得出以下结论：\n",
    "* 当数据集在280左右时，loss趋于稳定，大小趋近0.04。\n",
    "* 训练集有一定得过拟合，但过拟合程度并不是很严重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
